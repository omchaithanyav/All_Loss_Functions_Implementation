{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "Killed\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error (MSE) Loss\n",
    "# Binary Cross-Entropy Loss\n",
    "# Weighted Binary Cross-Entropy Loss\n",
    "# Categorical Cross-Entropy Loss\n",
    "# Sparse Categorical Cross-Entropy Loss\n",
    "# Dice Loss\n",
    "# KL Divergence Loss\n",
    "# Mean Absolute Error (MAE) / L1 Loss\n",
    "# Huber Loss\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error (MSE) Loss\n",
    "\"\"\"\n",
    "Mean Squared Error (MSE) loss is a commonly used loss function in regression problems, where the goal is to predict a continuous variable.\n",
    "The loss is calculated as the average of the squared differences between the predicted and true values. \n",
    "\n",
    "The formula for MSE loss is:\n",
    "MSE loss = (1/n) * sum((y_pred — y_true)²)\n",
    "\n",
    "Where:\n",
    "\n",
    "n is the number of samples in the dataset\n",
    "y_pred is the predicted value of the target variable\n",
    "y_true is the true value of the target variable\n",
    "\n",
    "The MSE loss is sensitive to outliers and can penalize large errors heavily, \n",
    "which may not be desirable in some cases. In such cases, other loss functions like Mean Absolute Error (MAE) or Huber Loss may be used instead.\n",
    "\"\"\"\n",
    "\n",
    "# Using Numpy\n",
    "def mse_loss_np(y_pred, y_true):\n",
    "    n = len(y_true) # n is numer of samples\n",
    "    mse = np.sum((y_pred - y_true) ** 2) / n # y_pred and y_true are NumPy arrays\n",
    "    return mse\n",
    "\n",
    "# Using Tensorflow\n",
    "def mse_loss_tf(y_pred, y_true):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    mse_loss = mse(y_true, y_pred)\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross-Entropy Loss\n",
    "\"\"\"\n",
    " Binary Cross-Entropy loss, also known as log loss, is a common loss function used in binary classification problems. \n",
    "It measures the difference between the predicted probability distribution and the actual binary label distribution.\n",
    "\n",
    "The formula for binary cross-entropy loss is as follows:\n",
    "\n",
    "L(y, ŷ) = -[y * log(ŷ) + (1 — y) * log(1 — ŷ)]\n",
    "\n",
    "where y is the true binary label (0 or 1), ŷ is the predicted probability (ranging from 0 to 1), and log is the natural logarithm.\n",
    "\n",
    "The first term of the equation calculates the loss when the true label is 1, and the second term calculates the loss when the true label is 0. \n",
    "The overall loss is the sum of both terms.\n",
    "\n",
    "When the predicted probability is close to the true label, the loss is low, and when the predicted probability is far from the true label, \n",
    "the loss is high. This loss function is commonly used in neural network models that use sigmoid activation functions in the output layer \n",
    "to predict binary labels.\n",
    "\"\"\"\n",
    "\n",
    "# y_true - true labels\n",
    "# y_pred - predicted probabilities\n",
    "\n",
    "# using Numpy\n",
    "def log_loss_np(y_pred, y_true):\n",
    "    # calculate the binary cross-entropy loss\n",
    "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)).mean()\n",
    "    return loss\n",
    "\n",
    "# using Tensorflow\n",
    "def log_loss_tf(y_pred, y_true):\n",
    "    # define the loss function\n",
    "    bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    # calculate the loss\n",
    "    loss = bce_loss(y_true, y_pred)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
